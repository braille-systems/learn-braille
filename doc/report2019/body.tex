\documentclass[main.tex]{subfiles}
\begin{document}
\section{Вступление. Постановка задачи}
В $\MakeUppercase{\romannumeral 19}$ веке Луи Брайль изобрёл рельефно-точечный шрифт, позволяющий незрячим на ощупь воспринимать текст, выдавленный на плотной бумаге. Каждый символ – шеститочие, всего 26 комбинаций. Для обучения азбуке Брайля существуют наборные буквенные кассы.

В данной работе предприняты шаги на пути к созданию системы, призванной помочь незрячему ученику в работе с буквенной кассой. Планируется создать программу, способную по фотоснимку рабочего поля распознать находящиеся на нём символы. Распознанный текст можно будет передать любому синтезатору речи, и незрячий, слушая, будет запоминать соответствие букв шеститочиям. Также можно создать обучающие приложения для мобильного телефона с выдачей и автоматической проверкой заданий, выполняемых с буквенной кассой.

Алгоритм распознавания включает сегментацию изображения (выделение участков, содержащих отдельные буквы) и классификацию символов. На данный момент исследована задача классификации изображений. Изображения представлены в чёрно-белом формате, поскольку буквы в наборной кассе чёрно-белые.

Задача классификации: на вход подаются прямоугольные матрицы вида $x \in \mathds{R} ^{m_1\times m_2}$, значение $x_{ij}$ соответствует насыщенности чёрного цвета в пикселе картинки. Построить оператор $x\rightarrow y, y \in 1, ..., K$ - номер класса, $K = 2^6 = 64$.

Поскольку число входных параметров велико (более ста) и правило классификации может быть очень сложным, решено применить алгоритмы машинного обучения. Задача машинного обучения: известны желаемые значения оператора в $n$ точках – тренировочный набор данных $(x^{(i)}, y^{(i)})_{i\in 1,...,n}$.

Требуется построить оператор, дающий как можно меньше ошибок на тренировочном наборе данных (и проверить его способность правильно классифицировать новые картинки, не присутствующие в тестовом наборе).

В работе сравниваются три классификационные модели: перцептрон, нейросеть и логистическая регрессия. Каждая функция-модель характеризуется своим набором параметров. Для нахождения оптимальных значений параметров при данном наборе тренировочных данных вводится функция ошибки $J_{(x^{(i)}, y^{(i)})}(W)$, где $W$ – вектор параметров. Задача сводится к минимизации функции $J_{(x^{(i)}, y^{(i)})}(W)$. Для минимизации используется алгоритм градиентного спуска.

\section{Описание и обоснование алгоритмов}
\subfile{parts/perceptron.tex}
\subfile{parts/nnet.tex}
\newpage
\section{Заключение}
В работе рассмотрены две линейные классификационные модели (однослойный перцептрон и логистическая регрессия) и одна нелинейная (нейронная сеть). Как показано в разделе «описание алгоритмов», на основе тренировочных данных $\{(x_i,y_i)\}$ можно построить модель, наилучшим образом приближающую этот набор данных. Под «наилучшим образом» подразумевается набор параметров модели $\theta$, дающий минимум функции стоимости $J(\theta|\{(x_i,y_i)\})$. Функция стоимости характеризует отклонение предсказаний классификатора от настоящих значений классов на тренировочном наборе данных.

Для линейных моделей удаётся задать выпуклую функцию стоимости (среднеквадратичное отклонение для перцептрона и кросс-энтропия в случае логистической регрессии), которая при заданном наборе $\{(x_i,y_i)\}$ имеет только один минимум. Как следствие, градиентный спуск при любых начальных значениях параметров за конечное число шагов может найти точку, в которой вектор параметров отличается от оптимального не более чем на любую наперёд заданную малую величину. Впрочем, необходимое число итераций заранее неизвестно, поэтому на практике итерационный процесс прерывают, когда норма вектора градиентов $\norm{\nabla J\left(\theta\right)}$ становится меньше некоторого порогового значения, которое выбирается сообразно с требуемой точностью и вычислительными ресурсами.

Функция стоимости нейронной сети в общем случае невыпуклая и содержит множество локальных минимумов. Тем не менее, часто удаётся найти достаточно глубокий локальный минимум. Нейронная сеть может формировать границы со сложным контуром, в то время как линейные модели применимы только к задачам с линейно разделимыми классами. В отдельных случаях задача с не линейно разделимыми классами может быть сведена к таковой путём трансформации пространства входных признаков, но чаще всего вид этой трансформации заранее неизвестен и применить её нельзя. Поэтому нейронные сети представляют собой гораздо более мощный и гибкий инструмент, чем линейные модели. К тому же способность образовывать границу сложной формы позволяет серьёзно увеличивать точность классификатора при добавлении новых точек в тренировочный набор данных – в отличие от линейных моделей, где граница лишь будет сдвинута, нейросеть может дать совсем иную конфигурацию параметров.
На следующем этапе работы планируется применить алгоритмы к распознаванию изображения как совокупности пикселей. Также планируется рассчитать несколько численных метрик изображений и попытаться обучить классификаторы, распознающие символы азбуки Брайля по набору метрик картинки.

\end{document}
